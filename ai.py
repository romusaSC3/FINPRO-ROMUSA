# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/195hQISS56BygUKVxFRQcYJJb-PWfmsDR
"""
from endpoint8 import imagepath 
import torch, torchvision
from torch import nn
from torch import optim
from torchvision.transforms import ToTensor
import torch.nn.functional as F
import matplotlib.pyplot as plt

import requests
from PIL import Image
from io import BytesIO

import copy

from sklearn.metrics import confusion_matrix
from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
import re
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import normalize
from sklearn.model_selection import ShuffleSplit
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, auc
import matplotlib.pyplot as plt
from torchvision import transforms
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
from torch import optim
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader,Dataset,ConcatDataset

from google.colab import drive
drive.mount('/content/drive')

class Net(nn.Module):

    def __init__(self):
        super().__init__()

        self.fc1 = nn.Linear(784,256)
        self.fc2 = nn.Linear(256,128)
        self.fc3 = nn.Linear(128, 64)
        self.fc4 = nn.Linear(64,11)

        self.dropout = nn.Dropout(0.2)
        
        ## TODO: Define the rest of the layers:
        # include another conv layer, maxpooling layers, and linear layers
        # also consider adding a dropout layer to avoid overfitting


    ## TODO: define the feedforward behavior
    def forward(self, x):
        # one activated conv layer
        x = x.view(x.shape[0], -1)
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.dropout(F.relu(self.fc2(x)))
        x = self.dropout(F.relu(self.fc3(x)))
        x = F.log_softmax(self.fc4(x), dim=1)

        
        # final output
        return x
cnn = Net()

continued_network = Net() #arsitektur model
continued_optimizer = optim.SGD(continued_network.parameters(), lr=0.001,
                                momentum=0.9) #optimizer

network_state_dict = torch.load("/content/drive/MyDrive/model/model.pth")
continued_network.load_state_dict(network_state_dict)

optimizer_state_dict = torch.load("/content/drive/MyDrive/model/optimizer.pth")
continued_optimizer.load_state_dict(optimizer_state_dict)

#read image path dan preprosesing image

from skimage.io import imread
from skimage.transform import resize
from skimage.util import invert

def load_image(image_path):
    # Load image array
    
    image = imread(image_path, as_gray = True)
    image=invert(image)
    # Reshape image
    image = resize(image, (28, 28))
    # Convert range from [0.0, 1.0] to [0, 255]
    image = image * 255
    return image

def load(path):
    image = imread(image_path)
    return image

# Load your image
image_path = imagepath #imagepath dari file endpoint8
images = load(image_path)
image = load_image(image_path)

# Predict your image
with torch.no_grad():
    # Flatten your image
    x = image.flatten()
    # Convert to tensor
    x = torch.FloatTensor(x)
    # Add batch dimension
    x = x.unsqueeze(0)
    # Predict output
    label_pred = continued_network(x)
    print(label_pred)
    label_pred = label_pred.argmax(dim = 1).item()

print(f"Predicted Label: {label_pred}")
fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)
ax1.imshow(images)
ax2.imshow(image, cmap='gray')
plt.show()
